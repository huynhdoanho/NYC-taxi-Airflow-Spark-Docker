version: "3.7"

x-airflow-common:
  &airflow-common
  build:
    context: ./
    dockerfile: ./Dockerfile.Airflow
  environment:
    - AIRFLOW__CORE__EXECUTOR=LocalExecutor
    - AIRFLOW__CORE__SQL_ALCHEMY_CONN=postgresql+psycopg2://postgres:postgres@postgres:5432/airflow
    - AIRFLOW__CORE__FERNET_KEY=FB0o_zt4e3Ziq3LdUUO7F2Z95cvFFx16hU8jTeR1ASM=
    - AIRFLOW__CORE__LOAD_EXAMPLES=False
    - AIRFLOW__CORE__LOGGING_LEVEL=INFO
    - ADDITIONAL_AIRFLOW_EXTRAS=apache.spark
  volumes:
    - ./dags:/opt/airflow/dags
    - ./airflow-data/logs:/opt/airflow/logs
    - ./airflow-data/plugins:/opt/airflow/plugins
    - ./airflow-data/airflow.cfg:/opt/airlfow/airflow.cfg
    - ./airflow-workdir:/home/workdir
#    - ./airflow-conf/spark-defaults.conf:/opt/airflow/spark/conf/spark-defaults.conf
    - ./dags/spark_app:/opt/bitnami/spark/app
  depends_on:
    - postgres
  networks:
    - de_network

services:
#  spark-master:
#    build:
#      context: ./
#      dockerfile: ./Dockerfile.Spark
#    container_name: "spark-master"
#    hostname: "spark-master"
#    environment:
#      - SPARK_MODE=master
#      - SPARK_LOCAL_IP=spark-master
#      - SPARK_RPC_AUTHENTICATION_ENABLED=no
#      - SPARK_RPC_ENCRYPTION_ENABLED=no
#      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
#      - SPARK_SSL_ENABLED=no
#    ports:
#      - "7077:7077"
#      - "8090:8080"
#    volumes:
##      - ./spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
#      - ./dags/spark_app:/opt/bitnami/spark/app
#    networks:
#      - de_network
#
#
#  spark-worker:
#    image: docker.io/bitnami/spark:3.3
#    deploy:
#      replicas: 2
#    environment:
#      - SPARK_MODE=worker
#      - SPARK_MASTER_URL=spark://spark-master:7077
#      - SPARK_WORKER_MEMORY=2G
#      - SPARK_WORKER_CORES=2
#      - SPARK_RPC_AUTHENTICATION_ENABLED=no
#      - SPARK_RPC_ENCRYPTION_ENABLED=no
#      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
#      - SPARK_SSL_ENABLED=no
#    networks:
#      - de_network

  minio:
    hostname: minio
    image: "minio/minio"
    container_name: minio
    ports:
      - "9001:9001"
      - "9000:9000"
    command: [ "server", "/data", "--console-address", ":9001" ]
    volumes:
      - ./minio:/data
    environment:
      - MINIO_ROOT_USER=minio
      - MINIO_ROOT_PASSWORD=minio123
      - MINIO_ACCESS_KEY=minio
      - MINIO_SECRET_KEY=minio123
    networks:
      - de_network


  mc:
    image: minio/mc
    container_name: mc
    hostname: mc
    environment:
      - AWS_ACCESS_KEY_ID=minio
      - AWS_SECRET_ACCESS_KEY=minio123
      - AWS_REGION=us-east-1
    entrypoint: >
      /bin/sh -c " until (/usr/bin/mc config host add minio http://minio:9000 minio minio123) do echo '...waiting...' && sleep 1; done; /usr/bin/mc mb minio/warehouse; /usr/bin/mc policy set public minio/warehouse; exit 0; "
    depends_on:
      - minio
    networks:
      - de_network


#  spark-notebook:
#    build:
#      context: ./notebooks
#      dockerfile: ./Dockerfile
#    container_name: "spark-notebooks"
#    user: root
#    environment:
#      - JUPYTER_ENABLE_LAB="yes"
#      - GRANT_SUDO="yes"
#    volumes:
#      - ./notebooks:/home/jovyan
#    ports:
#      - "4040:4040"
#      - "8888:8888"
#    networks:
#      - de_network


  postgres:
    image: postgres:12
    hostname: postgres
    container_name: postgres
    environment:
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres
      - POSTGRES_DB=airflow
      - POSTGRES_PORT=5434
      - POSTGRES_HOST=postgres
      - POSTGRES_HOST_AUTH_METHOD=trust
    volumes:
      - ./postgres:/var/lib/postgresql
    ports:
      - "5434:5432"
    networks:
      - de_network

  airflow-init:
    << : *airflow-common
    container_name: airflow_init
    entrypoint: /bin/bash
    command:
      - -c
      - ( airflow db init &&
        airflow users create
          --role Admin
          --username airflow
          --password airflow
          --email airflow@airflow.com
          --firstname airflow
          --lastname airflow )
    restart: on-failure
    networks:
      - de_network

  airflow-webserver:
    << : *airflow-common
    command: airflow webserver
    ports:
      - "8080:8080"
    container_name: airflow_webserver
    restart: always
    networks:
      - de_network

  airflow-scheduler:
    << : *airflow-common
    command: airflow scheduler
    container_name: airflow_scheduler
    restart: always
    networks:
      - de_network


#  mysql:
#    hostname: mysql
#    image: mysql:8.0
#    container_name: mysql
#    ports:
#      - "3306:3306"
#    environment:
#      - MYSQL_ROOT_PASSWORD=admin
#      - MYSQL_USER=admin
#      - MYSQL_PASSWORD=admin123
#      - MYSQL_DATABASE=nyc_taxi
#    volumes:
#      - ./mysql_data:/var/lib/mysql
#    networks:
#      - de_network


networks:
  de_network:
    driver: bridge
    name: de_network